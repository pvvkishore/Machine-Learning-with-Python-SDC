# Module 3: Supervised Learning - Regression

## Overview
Learn regression algorithms to predict continuous values. Master linear models and regularization techniques.

## Learning Objectives
- Understand regression mathematics
- Implement various regression algorithms
- Apply regularization to prevent overfitting
- Evaluate regression models appropriately

## Topics
1. **Simple Linear Regression**: One feature prediction
2. **Multiple Linear Regression**: Multiple features
3. **Polynomial Regression**: Non-linear relationships
4. **Ridge Regression (L2)**: Prevent overfitting
5. **Lasso Regression (L1)**: Feature selection
6. **Elastic Net**: Combined L1 and L2
7. **Evaluation Metrics**: MSE, RMSE, MAE, RÂ²

## Key Files
- `linear_regression_basics.ipynb` - Simple and multiple regression
- `polynomial_regression.ipynb` - Non-linear modeling
- `regularization_techniques.ipynb` - Ridge, Lasso, Elastic Net
- `regression_metrics.ipynb` - Evaluation methods

## Assignment 3: Housing Price Prediction
Build a model to predict house prices:
- Implement multiple regression algorithms
- Apply feature engineering
- Use regularization techniques
- Compare model performance
- Visualize predictions vs actual values

**Due**: End of Week 6

## Resources
- [Regression Tutorial](https://scikit-learn.org/stable/modules/linear_model.html)
- [Understanding Regularization](https://towardsdatascience.com/regularization-in-machine-learning)

## Checklist
- [ ] Implement linear regression from scratch
- [ ] Use Scikit-learn for various regression models
- [ ] Apply polynomial features
- [ ] Tune regularization parameters
- [ ] Calculate and interpret all metrics
- [ ] Visualize regression results
- [ ] Handle multicollinearity

---
**Next**: Module 4 - Classification Algorithms
